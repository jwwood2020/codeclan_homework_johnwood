---
title: "Week 01 - Weekend Homework"
output: html_notebook
---

```{r}
#load libraries
library(tidyverse)
library(janitor)
library(lubridate)
```


```{r}
#Read in .csv file and explore data
books <- read_csv("data/books.csv",
                 col_types = cols(
                    publication_date = col_date(format = "%m/%d/%Y")
                    )
                  ) 

#publication_date being read in as a character by default; specify as date format

csv_problems <- problems(books)

#identified 13 parsing failures caused by four records
#remove these four records if necessary. Is there a quick way to do this using problems()?




books <- clean_names(books)

#drop columns which will not be used in analysis
books <- books  %>% 
  select(
         -isbn,
         -isbn13,
         -x13
         ) 


#summarise to find missing values
#should be able to do this more efficiently without needing to list all?
books %>%   
  summarise(na_book_id = sum(is.na(book_id)), 
            na_title = sum(is.na(title)), 
            na_authors = sum(is.na(authors)), 
            na_average_rating = sum(is.na(average_rating)), 
            na_language_code = sum(is.na(language_code)), 
            na_num_pages = sum(is.na(num_pages)), 
            na_ratings_count = sum(is.na(ratings_count)), 
            na_text_reviews_count = sum(is.na(text_reviews_count)), 
            na_publication_date = sum(is.na(publication_date)), 
            na_publisher = sum(is.na(publisher))
  )
            


#This shorter version doesn't work - what is wrong?

#books %>% 
# summarise(
#   across(everything(),
#           sum(is.na())
#           )
#    )


#Remove the records with NAs

books <- books %>% 
  drop_na()


#impute num_pages to mean(num_pages) where less than 50
books <- books %>% 
 mutate(
   num_pages = if_else(num_pages < 50, 
                       round(mean(num_pages)),
                       num_pages
                       )
   )
                       

```





INITIAL EXPLORATION OF DATA

```{r}
books  %>% 
 select(language_code) %>% 
  distinct(language_code) %>% 
  arrange()

books %>% 
  summarise(
    across(
      c(authors, 
        title,
        language_code,
        publisher
        ),
      n_distinct
      )
    )
  

```

 
```{r}
#Add new variables: decade_published, book_size, rating_rounded, text_review_pc

books <- books %>% 
  mutate(
    book_size = case_when(
      num_pages < 200  ~ "Short",
      num_pages < 500  ~ "Medium",
      num_pages >= 500 ~ "Long",
      TRUE             ~ "Other"
      ),
    
    rating_rounded = round(average_rating),
    
    decade_published = case_when(
      year(publication_date) < 1900 ~ "A. pre-20thC",
      year(publication_date) < 1935 ~ "B. early 20thC",
      year(publication_date) < 1970 ~ "C. mid 20thC",
      year(publication_date) < 2000 ~ "D. late 20thC",
      year(publication_date) < 2010 ~ "E. 2000s",
      year(publication_date) < 2020 ~ "F. 2010s",
      year(publication_date) < 2022 ~ "G. 2020s",
      TRUE                          ~ "H. Other"
      ),
      
      text_review_pc = (text_reviews_count / ratings_count) * 100 
      )
      
    
    
    

```
 
 
 
```{r}
#Analysis by author

#Most reviewed across all their books, with average rating 
books %>% 
  select(authors,
         ratings_count,
         average_rating
         ) %>% 
  
  group_by(authors) %>%
  
  summarise(
    total_ratings = sum(ratings_count), 
    overall_rating = mean(average_rating)
    ) %>% 
  
  slice_max(total_ratings, n = 20) 

#Highest rated, subject to minimum number of reviews
books %>% 
  select(authors,
         ratings_count,
         average_rating
         ) %>% 
  
  group_by(authors) %>% 
  
  filter(ratings_count > 500) %>% 
  
  summarise(
    total_ratings = sum(ratings_count),
    overall_rating = mean(average_rating)
    ) %>% 
  
  slice_max(overall_rating, n = 20 )

#Lowest rated, subject to minimum number of reviews
books %>% 
  select(authors, 
         ratings_count,
         average_rating
         ) %>% 
  
  group_by(authors) %>% 
  
  filter(ratings_count > 500) %>% 
  
  summarise(
    total_ratings = sum(ratings_count),
    overall_rating = mean(average_rating)
  ) %>% 
  
  slice_min(overall_rating, n =20)

#Authors with most number of books

books %>% 
  select(
      authors,
      title
    ) %>% 
  
  group_by(authors) %>% 
  
  summarise(
    total_titles = n_distinct(title)
    ) %>%
  
  slice_max(total_titles, n =20)

#Average number of books per author - not working
books %>% 
  select(
      authors,
      title
    ) %>% 
  
  group_by(authors) %>% 
  mutate(total_titles = n_distinct(title)) %>% 
  summarise(average_titles = mean(total_titles))




```
 
 
 
```{r}
#Analysis by book title
#Most reviewed, average rating of these
  
books %>% 
  select(title, 
         ratings_count, 
         average_rating) %>% 
  
  group_by(title) %>%
  
  summarise(
    total_ratings = sum(ratings_count), 
    overall_rating = mean(average_rating)
    ) %>% 
  
  slice_max(total_ratings, n = 20) 

#Highest rated, subject to minimum number of reviews
books %>% 
  select(title, 
         authors,
         ratings_count,
         average_rating
         ) %>% 
 
  filter(ratings_count > 500) %>% 
  
  slice_max(average_rating, n = 20)


#Lowest rated, subject to minimum number of reviews
books %>% 
  select(title,
         authors,
         ratings_count,
         average_rating
         ) %>% 
  
  filter(ratings_count > 500) %>% 
  
  slice_min(average_rating, n = 20)
```
 
 
 
```{r}
#Analysis by publication decade
books %>%
  select(
    title,
    decade_published,
    ratings_count,
    average_rating
    ) %>% 
  
  group_by(decade_published) %>% 
  
  summarise(
    total_titles = n_distinct(title),
    total_ratings = sum(ratings_count),
    mean(average_rating)
    ) %>% 
  
  arrange(decade_published)


  
```
 
 
```{r}
#Summary of ratings

books %>% 
  summarise(
    mean(average_rating, na.rm = TRUE),
    sd(average_rating, na.rm = TRUE)
  )


books %>% 
  group_by(rating_rounded) %>%
  
  summarise(
    number_of_ratings = sum(rating_rounded),
    mean(average_rating)
    ) 
  



```
 

```{r}
#Book Length
books %>% 
  summarise(
    max(num_pages, na.rm =TRUE),
    median(num_pages, na.rm = TRUE),
    mean(num_pages, na.rm = TRUE)
  )

books %>%
  group_by(book_size) %>%
  
  summarise(number_books = n())
  
books %>% 
  select(title,
         authors,
         num_pages) %>% 
  slice_max(num_pages, n =10 )
  
```

OTHER ANALYSIS THAT COULD BE CARRIED OUT
 
 - title length: longest, shortest, average, most common
 - title: most common words 
 - publishers: number of publishers, number of books per publisher, number of authors per publisher, number of ratings/reviews by publisher, average rating by publisher
 