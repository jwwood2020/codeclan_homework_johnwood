---
title: "Week 11 Day 2 HW"
output: html_notebook
---

```{r}
library(rpart) #for creating decision tree with rpart()
library(rpart.plot) #for plotting decision tree with rpart.plot()
library(tidyverse)
library(GGally) #for ggpairs()
library(janitor) #for tabyl()
library(modelr) #for adding predictions
library(caret) #for confusion matrix conf_mat()
library(ranger) #for random forests
```


```{r}
titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```

```{r}
titanic_set %>% 
  summarise(across(.fns = ~sum(is.na(.x))))
```
QUESTION 1
```{r}
titanic_trim <- titanic_set %>% 
  filter(is.na(survived) == FALSE) %>% 
  mutate(sex = as.factor(sex),
         class = factor(pclass, levels = c(3,2,1), labels = c("Lower", "Middle", "Upper")), 
         survived_flag = factor(survived, levels = c(0,1), labels = c("Died", "Survived")),
         embarked = as.factor(embarked),
         age_status = case_when(age <= 16 ~ "child",
                                age > 16 ~ "adult")) %>% 
  select(-c("X1", "passenger_id", "age", "name", "ticket", "fare", "pclass", "cabin", "survived")) %>% 
  drop_na()
```

```{r}
titanic_trim %>% 
  summarise(across(.fns = ~sum(is.na(.x))))
```
QUESTION 2
```{r}
titanic_trim %>% 
  ggpairs(columns = c("class", "sex", "sib_sp", "survived_flag"),
          progress = FALSE)
```

This shows that there is a strong relationship for survival with sex and pclass.

```{r}
titanic_trim %>% 
  ggpairs(columns = c("parch", "embarked", "age_status", "survived_flag"),
          progress = FALSE)
```
This suggests relationships with parch and embarked.

So from these plots I would expect that the following variables could be useful as predictors:
- sex
- pclass
- parch
- embarked

QUESTION 3: CREATE TEST/TRAINING DATA
```{r}
n_data <- nrow(titanic_trim)

test_index <- sample(1:n_data, size = n_data * 0.2)

titanic_test <- slice(titanic_trim, test_index)

titanic_train <- slice(titanic_trim, -test_index)
```

```{r}
titanic_train %>% 
  tabyl(survived_flag)
```

```{r}
titanic_test %>% 
  tabyl(survived_flag)
```

```{r}
titanic_trim %>% 
  tabyl(survived_flag)
```

Split of 80:20 between train/test to give a reasonable size of dataset for each.
Tables above show that the sets are fairly well balanced on survival.


QUESTION 4: DECISION TREE
```{r}
#Fit model
titanic_fit <- rpart(
  formula = survived_flag ~ .,
  data = titanic_train,
  method = "class"
)
```

```{r}
#Plot decision tree
rpart.plot(
  titanic_fit, 
  yesno = 2,
  fallen.leaves = TRUE,
  faclen = 6,
  digits = 4,
  type = 4
)

```
QUESTION 5
This decision tree shows that the most informative predictive factor is sex, followed by 
class then embarked.
The decision tree is looking at *survival*.
- Males have a 19.9% probability of survival, the lowest of all groups
- Females have a 75.4% probability of survival
- Females in middle and upper class have the highest probability of survival at 96%
- Females in lower class have a 42.3% probability of survival
- Females in lower class with embarked of Q or S have a 35.6% probability of survival
- Females in lower class with embarked of C have a 71.4% probability of survival



QUESTION 6
```{r}
titanic_test_pred <- titanic_test %>% 
  add_predictions(titanic_fit, type = "class")
```

```{r}
confusionMatrix(titanic_test_pred$pred, titanic_test_pred$survived_flag)
```

This summary tells us the following about the predictive power of the model:

- The Accuracy shows that the model is correct 73% of the time
- The True Positive Rate (sensitivity) is 0.9375, so it correctly identifies as survived (= positive)
a high number of outcomes
- The True Negative Rate (specificity) is 0.4677, so it is poor at correctly identifying actual negatives (= died)


EXTENSION

```{r}
library(ranger)

rf_classifier <- ranger(survived_flag ~ ., 
                        data = titanic_train, 
                        importance = "impurity", 
                        num.trees = 1000, 
                        mtry = 3,
                        min.node.size = 3)

rf_classifier
```

```{r}
importance(rf_classifier)
```
```{r}
summary(rf_classifier)
```

```{r}
titanic_test_rf_pred <- titanic_test %>%
  mutate(pred = predict(rf_classifier, data = titanic_test)$predictions)
```

```{r}
confusionMatrix(titanic_test_rf_pred$pred, titanic_test_rf_pred$survived_flag)
```


#CODECLAN PROVIDED CODE
```{r}
control <- trainControl(
  method = "repeatedcv", 
  number = 5, 
  repeats = 10
)

tune_grid = expand.grid(
  mtry = 1:6,
  splitrule = c("gini", "extratrees"),
  min.node.size = c(1, 3, 5)
)
```

```{r}
rf_tune <- train(
  survived_flag ~ ., 
  data = titanic_train, 
  method = "ranger",
  metric = "Kappa",
  num.trees = 1000,
  importance = "impurity",
  tuneGrid = tune_grid, 
  trControl = control
)

plot(rf_tune)
rf_tune
```

